{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01abdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, time, random\n",
    "\n",
    "import numpy.typing as npt\n",
    "\n",
    "from src.core.sequential import Sequential\n",
    "from src.core.lstm import BiLSTM\n",
    "from src.core.layers import Linear, SigmoidActivation, ReLU, sigmoid\n",
    "from src.core.loss import MSELoss, SigmoidWeightedBCELoss, SigmoidWeightedBCEFocalLoss\n",
    "from src.core.optimizers import Adam\n",
    "from src.core.cosine_scheduler import CosineScheduler\n",
    "from src.projects.noise_reduction.fourier_transform import compute_stft_vectorized, compute_stft_inv, convert_to_db, filter_downsample\n",
    "from src.projects.noise_reduction.visualizations import plot_spectrogram, plot_loss_mask, plot_denoising_comparison\n",
    "from src.utils.save_and_load_model import save_model, load_model\n",
    "from src.utils.save_and_load_checkpoint import save_checkpoint, load_checkpoint\n",
    "\n",
    "Tensor = npt.NDArray[cp.float64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a34306",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_path = r\"D:\\Datasets\\Clean and Noisy Audio Dataset 16kHz Spectrogram Magnitudes\\train\\noisy\\p234_002.npy\"\n",
    "clean_path = r\"D:\\Datasets\\Clean and Noisy Audio Dataset 16kHz Spectrogram Magnitudes\\train\\clean\\p234_002.npy\"\n",
    "\n",
    "# We already preprocessed the audios to 16kHz\n",
    "sr, N, hop = 16000, 512, 256\n",
    "\n",
    "n_spec = cp.load(noisy_path)\n",
    "c_spec = cp.load(clean_path)\n",
    "\n",
    "noisy_db = convert_to_db(n_spec, N, is_raw_magnitude=False).get()\n",
    "clean_db = convert_to_db(c_spec, N, is_raw_magnitude=False).get()\n",
    "\n",
    "plot_loss_mask(noisy_db, clean_db, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoiceDataset:\n",
    "    def __init__(self, path, duration, sr, N, hop, batch_size):\n",
    "        self.duration = duration\n",
    "        self.sr = sr\n",
    "        self.N = N\n",
    "        self.hop = hop\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.train_split = []\n",
    "        self.val_split = []\n",
    "        \n",
    "        self.num_batches = {\n",
    "            \"train\" : None,\n",
    "            \"val\" : None\n",
    "        }\n",
    "        \n",
    "        for split in ['train', 'val']:\n",
    "            clean_dir_path = os.path.join(path, split, 'clean')\n",
    "            noisy_dir_path = os.path.join(path, split, 'noisy')\n",
    "            \n",
    "            # We know the names are the same in both directories, same amount of files\n",
    "            clean_files = sorted(os.listdir(clean_dir_path))\n",
    "            noisy_files = sorted(os.listdir(noisy_dir_path))\n",
    "            \n",
    "            self.num_batches[split] = len(clean_files) // batch_size\n",
    "            \n",
    "            for batch_index in range(self.num_batches[split]):\n",
    "                start = batch_index * batch_size\n",
    "                end = start + batch_size\n",
    "                \n",
    "                batch_paths = []\n",
    "                for i in range(start, end):\n",
    "                    c_path = os.path.join(clean_dir_path, clean_files[i])\n",
    "                    n_path = os.path.join(noisy_dir_path, noisy_files[i])\n",
    "                    \n",
    "                    batch_paths.append((c_path, n_path))\n",
    "                    \n",
    "                if split == \"train\":\n",
    "                    self.train_split.append(batch_paths)\n",
    "                elif split == 'val':\n",
    "                    self.val_split.append(batch_paths)\n",
    "                    \n",
    "    def shuffle_train_data(self):\n",
    "        all_training_paths = []\n",
    "        \n",
    "        for batch_index in range(self.num_batches['train']):\n",
    "            all_training_paths.extend(self.train_split[batch_index])\n",
    "            \n",
    "        self.train_split = []\n",
    "            \n",
    "        random.shuffle(all_training_paths)\n",
    "        \n",
    "        for batch_index in range(self.num_batches['train']):\n",
    "            start = batch_index * self.batch_size\n",
    "            end = start + self.batch_size\n",
    "            \n",
    "            batch_paths = []\n",
    "            \n",
    "            for i in range(start, end):\n",
    "                c_path, n_path = all_training_paths[i]\n",
    "                \n",
    "                batch_paths.append((c_path, n_path))\n",
    "                \n",
    "            self.train_split.append(batch_paths)\n",
    "                        \n",
    "    def get_batch(self, split='train', index=0):\n",
    "        if split == 'train':\n",
    "            batch_list = self.train_split[index]\n",
    "        elif split == 'val':\n",
    "            batch_list = self.val_split[index]\n",
    "            \n",
    "        X_batch, Y_batch, db_noisy_batch, db_clean_batch = [], [], [], [] # LM = Loss Mask\n",
    "\n",
    "        for clean_path, noisy_path in batch_list:\n",
    "            n_mag = cp.load(noisy_path)\n",
    "            c_mag = cp.load(clean_path) \n",
    "            \n",
    "            db_noisy = convert_to_db(n_mag, self.N, is_raw_magnitude=True)\n",
    "            db_clean = convert_to_db(c_mag, self.N, is_raw_magnitude=True)\n",
    "            \n",
    "            # x_new = (x - center) / radius where center is (A + B) / 2 (center of original distribution, we center data around 0) and radius is (B - A) / 2 (how much the data is off 0 at most) \n",
    "            # x_input = (x_input - (-100 + 0) / 2) / ((0 - (-100)) / 2) # bc our [A, B] is [-100, 0]\n",
    "            x_input = (db_noisy + 40) / 40 # Same as line above\n",
    "            x_input = cp.clip(x_input, -1.0, 1.0, out=x_input) # We clip if the magnitude in convert_to_db was bigger than 1\n",
    "\n",
    "            mask = c_mag / (n_mag + 1e-9) # target_mask = cp.abs(clean) / cp.abs(noisy) -> this means \"how much of clean signal is in the noisy?\" If its 100% then its 1, if 0% then 0.\n",
    "            mask = cp.clip(mask, 0, 1, mask)\n",
    "            \n",
    "            X_batch.append(x_input)\n",
    "            Y_batch.append(mask)\n",
    "            db_noisy_batch.append(db_noisy)\n",
    "            db_clean_batch.append(db_clean)\n",
    "            \n",
    "        X_stack, Y_stack, LM_stack = cp.stack(X_batch), cp.stack(Y_batch), (cp.stack(db_noisy_batch), cp.stack(db_clean_batch))\n",
    "            \n",
    "        del X_batch, Y_batch, db_noisy_batch, db_clean_batch\n",
    "        \n",
    "        return X_stack, Y_stack, LM_stack\n",
    "    \n",
    "    def summary(self):\n",
    "        print(f\"Train batches: {self.num_batches['train']}\")\n",
    "        print(f\"Validation batches: {self.num_batches['val']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e12fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"D:\\Datasets\\Clean and Noisy Audio Dataset 16kHz Spectrogram Magnitudes\"\n",
    "duration = 2 # 2 sec per sample, if less we pad\n",
    "sampling_rate = 16000\n",
    "N, hop = 512, 256\n",
    "batch_size = 128\n",
    "\n",
    "input_dim = N // 2 + 1 # amount of bins\n",
    "hidden_dim = 256 # for BiLSTM its 256 * 2 = 512 theoretically\n",
    "dense_dim = 512\n",
    "output_dim = N // 2 + 1 # also amount of bins (the mask)\n",
    "\n",
    "max_lr = 1e-3\n",
    "min_lr = 1e-5\n",
    "warmup_epochs = 0\n",
    "total_epochs = 120\n",
    "\n",
    "gamma = 0.25\n",
    "\n",
    "dataset = VoiceDataset(dataset_path, sampling_rate, duration, N, hop, batch_size)\n",
    "\n",
    "model = Sequential([\n",
    "    BiLSTM(input_dim, hidden_dim),\n",
    "    Linear(2 * hidden_dim, output_dim, act='sigmoid'), # Because outputs are returned reshapes, we can apply two times with flattening logic.\n",
    "])\n",
    "\n",
    "loss_fn = SigmoidWeightedBCEFocalLoss(gamma)\n",
    "\n",
    "params = model.params()\n",
    "optimizer = Adam(params, max_lr, beta1=0.9, beta2=0.999, eps=1e-8)\n",
    "scheduler = CosineScheduler(max_lr, min_lr, warmup_epochs, total_epochs)\n",
    "\n",
    "learnable_layers = {\n",
    "    \"model\" : model\n",
    "}\n",
    "\n",
    "model.summary()\n",
    "dataset.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e54c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'models/best_denoise_focal.npz'\n",
    "resume_training = False\n",
    "print_every = 100\n",
    "\n",
    "start_epoch = 1\n",
    "best_loss = float('inf')\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "if resume_training:\n",
    "    start_epoch, best_loss, train_loss_history, val_loss_history = load_checkpoint(checkpoint_path, learnable_layers, optimizer)\n",
    "    start_epoch += 1 # We resume from one further than when we saved\n",
    "    \n",
    "for epoch in range(start_epoch, total_epochs+1):\n",
    "    learning_rate = scheduler.get_lr(epoch)\n",
    "    \n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Train\n",
    "    for batch_index in range(dataset.num_batches['train']):\n",
    "        \n",
    "        X_batch, Y_batch, (db_noisy, db_clean) = dataset.get_batch('train', batch_index)\n",
    "        \n",
    "        speech_to_keep = (db_clean + 80) / 80 # scale to [0, 1]\n",
    "        speech_to_keep = cp.clip(speech_to_keep, 0, 1) # How much we want to keep it\n",
    "        noise_to_delete = cp.clip(db_noisy - db_clean, 0, 80) / 80 # How much we want to zero it out\n",
    "        \n",
    "        loss_mask = cp.maximum(speech_to_keep, noise_to_delete) # take max of masks\n",
    "        loss_mask = loss_mask / cp.mean(loss_mask) # normalization drives important pixels even higher\n",
    "        \n",
    "\n",
    "        logits = model.forward(X_batch)\n",
    "        loss, mask = loss_fn.forward(logits, Y_batch, loss_mask)\n",
    "        \n",
    "        epoch_train_losses.append(loss.get())\n",
    "        \n",
    "        dlogits = loss_fn.backward()\n",
    "        dinput = model.backward(dlogits)\n",
    "        \n",
    "        optimizer.step(learning_rate)\n",
    "        \n",
    "        if (batch_index + 1) % print_every == 0 or batch_index == 0: # Print the first batch too\n",
    "            end_time = time.time()\n",
    "            diff = end_time - start_time\n",
    "            \n",
    "            total_steps = total_epochs * dataset.num_batches['train']\n",
    "            completed_steps = ((epoch - 1) * dataset.num_batches['train']) + (batch_index + 1) \n",
    "            progress = completed_steps / total_steps * 100\n",
    "            \n",
    "            print_train_loss = np.mean(epoch_train_losses[-print_every:]) if batch_index != 0 else epoch_train_losses[0]\n",
    "            bpm = 60 / diff * print_every if batch_index != 0 else 60 / diff\n",
    "            print(f\"Epoch: {epoch} | Batch: {batch_index+1} | Loss: {np.mean(epoch_train_losses):.6f} | BPM: {bpm:.2f} batches | Progress: {progress:.2f}%\")\n",
    "            print(f\"Mask max: {cp.max(mask)} | Mask min: {cp.min(mask)}\")\n",
    "            \n",
    "            start_time = time.time()\n",
    "    \n",
    "    # Eval\n",
    "    for batch_index in range(dataset.num_batches['val']):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        X_batch, Y_batch, (db_noisy, db_clean) = dataset.get_batch('val', batch_index)\n",
    "        \n",
    "        speech_to_keep = (db_clean + 80) / 80 # same as in training loop\n",
    "        speech_to_keep = cp.clip(speech_to_keep, 0, 1) \n",
    "        noise_to_delete = cp.clip(db_noisy - db_clean, 0, 80) / 80 \n",
    "        \n",
    "        loss_mask = cp.maximum(speech_to_keep, noise_to_delete) \n",
    "        loss_mask = loss_mask / cp.mean(loss_mask)\n",
    "        \n",
    "        logits = model.forward(X_batch)\n",
    "        loss, mask = loss_fn.forward(logits, Y_batch, loss_mask)\n",
    "        \n",
    "        epoch_val_losses.append(loss.get())\n",
    "    \n",
    "    ave_train_loss = np.mean(epoch_train_losses)\n",
    "    ave_val_loss = np.mean(epoch_val_losses)\n",
    "    \n",
    "    train_loss_history.append(ave_train_loss) # already Numpy\n",
    "    val_loss_history.append(ave_val_loss) # same\n",
    "    \n",
    "    print(f\"Finished epoch {epoch}. Training Loss: {np.mean(ave_train_loss):.6f} Val Loss: {np.mean(ave_val_loss):.6f}\")\n",
    "    \n",
    "    if ave_val_loss < best_loss: # pick based on validation\n",
    "        best_loss = ave_val_loss\n",
    "        save_checkpoint(checkpoint_path, learnable_layers, optimizer, epoch, best_loss, train_loss_history, val_loss_history)\n",
    "        \n",
    "    dataset.shuffle_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65caafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loss_plot = False\n",
    "\n",
    "plt.figure(figsize=(16 ,8))\n",
    "\n",
    "plt.plot(train_loss_history, label='Training Loss')\n",
    "plt.plot(val_loss_history, label='Validation Loss')\n",
    "\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "if save_loss_plot:\n",
    "    plt.savefig(\"src/projects/noise_reduction/tests/training_val_loss.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_recording(audio: Tensor, N: int, hop: int, model: Sequential):\n",
    "\n",
    "    spec, orig_len = compute_stft_vectorized(audio, N, hop) # (num_frames, K), we need orig_len to reverse the padding\n",
    "    mag = convert_to_db(spec, N, is_raw_magnitude=False) # (num_frames, K)\n",
    "    \n",
    "    mag_norm = (mag + 40) / 40 # Same normalization as training as data ranges between (-80, 0)\n",
    "    mag_norm = cp.clip(mag_norm, -1.0, 1.0) # safety clip\n",
    "\n",
    "    logits = model.forward(mag_norm[cp.newaxis, :, :]).squeeze() # add new axis for B=1\n",
    "    mask = sigmoid(logits)\n",
    "    \n",
    "    cleaned_spec = spec * mask # scales imaginary and real components accordingly (just the magnitude)\n",
    "    audio = compute_stft_inv(cleaned_spec, orig_len, N, hop)\n",
    "    \n",
    "    return audio, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf024e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = \"models/best_denoise_focal.npz\"\n",
    "load_model(best_model_path, learnable_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_audio_path = r\"C:\\Users\\horec\\Downloads\\noisy_2.wav\"\n",
    "output_audio_path = r\"C:\\Users\\horec\\Downloads\\clean_2.wav\"\n",
    "\n",
    "noisy_audio, _ = lb.load(noisy_audio_path, sr=sampling_rate)\n",
    "clean_audio, mask = clean_recording(noisy_audio, N, hop, model)\n",
    "\n",
    "n_spec, _ = compute_stft_vectorized(noisy_audio, N, hop) # both are in the complex plane\n",
    "c_spec, _ = compute_stft_vectorized(clean_audio, N, hop)\n",
    "\n",
    "plot_denoising_comparison(n_spec, c_spec, mask.get(), sampling_rate, N, hop, save_path=\"src/projects/noise_reduction/tests/denoising_comparison_2\")\n",
    "\n",
    "sf.write(output_audio_path, clean_audio.get(), sampling_rate)\n",
    "print(f\"Saved audio to: {output_audio_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
